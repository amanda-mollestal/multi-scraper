# Mall för inlämning laboration 1, 1dv610

## Checklista
  - [x] Jag har skrivit all kod och reflektioner själv. Jag har inte använt mig av andras kod för att lösa uppgiften.
  - [x] Mina testresultat är skrivna utifrån utförd testning ( och inte teoretiskt: "det bör fungera" :) )
  - [x] Koden är objektorienterad
  - [x] Jag har skrivit en modul som riktar sig till programmerare

## Egenskattning och mål
  - [ ] Jag är inte klar eftersom jag vet att jag saknar något. (Då skall du inte lämna in! Lämna då istället in på restlaboration.)
  - [x] Jag eftersträvar med denna inlämning godkänt betyg (E-D)
    - [x] De flesta testfall fungerar
    - [x] Koden är förberedd på Återanvändning
    - [x] All kod samt historik finns i git 
    - [x] Kodkvaliterskraven är ifyllda
    - [x] Reflektion är skriven utifrån bokens kapitel 
  - [ ] Jag eftersträvar med denna inlämning högre betyg (C-B) och anser mig uppfylla alla extra krav för detta. 
    - [x] Samtliga testfall är skrivna    
    - [ ] Testfall är automatiserade
    - [x] Det finns en tydlig beskrivning i hur modulen skall användas (i git)
    - [ ] Kodkvalitetskraven är varierade 
  - [ ] Jag eftersträvar med denna inlämning högsta betyg (A) 

Förtydligande: Examinator kommer sätta betyg oberoende på vad ni anser. 

## Återanvändning
Det finns tydliga instruktioner för användning i README filen --> [README FILEN](/README.md)

## Beskrivning av min kod
Tydlig beskrivning av klass och metoder finns i README filen --> [README FILEN](/README.md)

## Hur jag testat
Taget från testrapport.md eftersom jag trodde vi skulle svara på allt detta i sparata filer. 

I have created a tests.js file that acts as a test application for this module. It contains 8 tests that each test 1 of the 8 public methods. 

A test itelf is a method that calls the method it's testing and checks if the response is as expected. The results will log as either 'passed' or 'failed' in your console. Command to run tests: npm test.

### Testfall
Lista de enskilda testfallen. **Fetmarkera** sådant som du själv fyllt i. En rad per testfall. Om ni använder vertyg för testning kan ni ha en bild här med testrapporten. Tänk på att kommunicera till mig. Vad fungerar?, vad fungerar inte? Hur är det testat? Vilka delar testas inte?

|      What to be tested     | How it's tested                | Passed/Failed |
|:--------------------------:|--------------------------------|---------------|
| canUrlBeScraped            | testCanUrlBeScraped            | Passed        |
| getHtmlFromUrl             | testGetHtmlFromUrl             | Passed        |
| scrapeHtmlForTags          | testScrapeHtmlForTags          | Passed        |
| scrapeHtmlForTagAttribute  | testScrapeHtmlForTagAttribute  | Passed        |
| getPageTitleFromUrl        | testGetPageTitleFromUrl        | Passed        |
| getAllImageSources         | testGetAllImageSources         | Passed        |
| getAllHrefFromUrl          | testGetAllHrefFromUrl          | Passed        |
| turnRelativeToAbsoluteUrls | testTurnRelativeToAbsoluteUrls | Passed        |


## Kodkvalitetskrav

**Fetmarkera** de "regler" som används ur CC. Ni kan frångå tabellformat om ni vill. Skapa direktlänkar till er kod där det är lämpligt. Skriv så att jag kan förstå.

### Namngivning


|     Namn och   förklaring                                                                                                                                                                                                                                                      |     Reflektion   och regler ifrån boken                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         |
|--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|
|     canUrlBeScraped(url)   – metod som kollar om en URL går att skrapa html från och returnerar true eller   false.                                                                                                                                                            |     **Method   Names**: Jag försökte följa standarden med att accessors och mutators bör   namnges som get, set och is. Men canUrlBeScraped kändes lättare för ögat och   hjärnan än isScraperAbleToScrapeUrl eller isUrlScrapable (vilket inte ens är   ett riktigt ord och hade brutit mot **Don’t Be Cute**)                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         |
|     (TVÅ FÖR   ATT JÄMFÖRA)           getHtmlFromUrl(url)   – en metod som skrapar en url och returnerar html-koden.            scrapeHtmlForTags(html,   tag) – metod som skrapar html och returnerar en array med alla taggar som   matchar det angivna tag-namnet.          |     **Pick One   Word per Concept**: Alla mina metoder returnerar något. Jag har försökt   vara konsekvent men ändå tydlig i min namngivning och därför så skiljer sig   namnen åt, alla börjar inte t.ex. inte på get fast att dem returnerar något.           **Make   Meaningful Distinctions**: Det har blivit så här just för att jag försökt göra   tydligare och meningsfulla skillnader på metoderna. Metoderna som   bara tar en URL som parameter börjar med get och följer getXFromUrl – där X   är det som returneras,           Metoderna som   tar HTML och något mer börjar med scrape och följer scrapeHtmlForX - där X är det som returneras.              Jag inser   dock nu att det kanske bara har blivit mer komplicerat. getHtmlFromUrl kunde haft   namnet scraperUrlForHtml. Då hade alla följt samma format. Jag kunde haft en   formatering men ändå gjort meningsfulla skillnader.    |
|     getAllImageSources(url)   – en metod som skrapar en url och returnerar en array med alla img sources.                                                                                                                                                                      |     För att bygga   vidare på förra så har jag inte varit konsekvent med namngivningen. Denna   borde heta getAllImageSourcesFromUrl(). Men hade jag varit riktigt konsekvent   och tydlig med alla namn så hade ett bättre namn varit   scrapeUrlForAllImageSources.           **Avoid Disinformation**:   Något jag ser nu (när jag skriver tillfälligt i ett word-dokument) är att   getAllImageSources ser ut att ha tre små (lll). Detta ser inte lika otydligt   ut i min kod editors font men hade kanske kunnat vara väldigt otydligt i en   annan.                                                                                                                                                                                                                                                                                                                                                         |
|     turnRelativeToAbsoluteUrls(url,   array) – Tar den URL man skrapat från och den en array av relativa eller en   blandning av relativa/absoluta URLs man skrapat och gör varje relativ till   absolut.                                                                      |     **Use   Intention-Revealing Names**: Detta namn kunde varit längre för tydlighetens   skull t.ex. turnArrayOfRelativeToAbsolutUrls eller turnArrayOfRelativeOrMixedToAbsoluteUrls.     Jag är dock   fortfarande i stadiet där jag inte vet var gränsen mellan tydligt och förvirrande   långt är.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              |
|     scrapeHtmlForTagAttribute(html,   tag, attribute)                                                                                                                                                                                                                          |     **Use   Intention-Revealing Names** och **Make Meaningful Distinctions**: Jag misstänker   att om man inte läst min dokumentation så kan man bli förvånad över att man   får tillbaka en array med attribute-värden. Det kan därför skapa fler frågor   än svar. Möjligtvis scrapeHtmlForAllTagAttributes hade varit   tydligare.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   |

### Funktioner

FÖRLÅT FÖR HUR KODEN SER UT. Jag gjorde tabeller i andra filer för jag visste inte att det var i denna filen vi skulle svara förrens nu på natten när jag skulle lämna in.

|     Metodnamn och   kod                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       |     Antal rader (ej   radbrytningar)    |     Reflektion                                                                                                                                                                                                                                                                                                                                                                                                                                      |
|-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|-----------------------------------------|-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|
|   ```   scrapeHtmlForTags = async (html,   tag) => {           const $ = load(html)           const tagArray = []                      $(`${tag}`).each(function () {                 const thisTag = {             name: $(this)[0].name,             type: $(this)[0].type,             textContent: $(this).text(),             attributes:   JSON.parse(JSON.stringify($(this)[0].attribs)),           }                      tagArray.push(thisTag)         })               return tagArray       }   ```                                                                                                                                                                                                                       |     12                                  |     Small:   Funktioner bör vara så små som dem kan vara. Jag tror att med lite extra tankekraft   så hade jag kunnat bryta ut och få ner antal rader.  Do one thing:   Man kan argumentera att denna funktion gör två saker 1. Letar efter tag som   matchar 2. Gör om till tag-objekt med användbar information. Nr 2 kan ha   varit en utbruten funktion.                                                                                        |
|  ```    turnRelativeToAbsoluteUrls = (url,   array) => {                 this.#validateArray(array)           const urlRightFormat = this.#makeUrlRightFormat(url)            const baseUrl = this.#getBaseUrl(urlRightFormat)           const arrayCopy = array.slice()                 for(let i = 0; i < arrayCopy.length; i++) {                 const givenUrl = `${arrayCopy[i]}`                 if(!givenUrl.startsWith('http')) {                   if (givenUrl.startsWith(`/`)) {               arrayCopy[i] = baseUrl + givenUrl             } else {               arrayCopy[i] = urlRightFormat +   givenUrl             }           }                        }                 return arrayCopy               }  ```   |     15                                  |     Small och   Do One Thing och Blocks and Indenting: Även här hade jag nog haft   möjlighet att kämpa ner koden några rader samt bryta ut någon funktionalitet   t.ex. någon if-sats. Enligt boken bör inga funktioner vara stora nog att ha ”nested   structures”.                 Have No   Side Effects: Jag är noga med att göra kopia av den array jag får in för   att sedan göra ändringar på och returnera kopian av original arrayn.     |
|  ```    canUrlBeScraped = async (url)   => {           try {           const tryToScrape = await   this.getHtmlFromUrl(url)           return true           } catch (error) {           return false           }       }    ```                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       |     6                                   |     Commans   query separation: Funktioner ska antingen göra något eller svara på något,   inte både och. Därför svarar bara denna funktion om det går att skrapa denna url,   den skickar inte med någon html-kod även om det gick.                                                                                                                                                                                                                |
| ```     scrapeHtmlForTagAttribute = async   (html, tag, attribute) => {                 const $ = load(html)           const attributeArray = []                 $(`${tag}`).each(function () {             attributeArray.push($(this).attr(`${attribute}`))           })         return attributeArray       }     ```                                                                                                                                                                                                                                                                                                                                                                                                              |     6                                   |     Function   Argument: Det bästa är när funktioner inte behöver parametrar men tyvärr   behöver denna tre (triadic). Detta gör funktionen komplicerad att använda.                                                                                                                                                                                                                                                                                |
|   ```   getAllHrefFromUrl   = async (url) => {         const html = await   this.getHtmlFromUrl(url)                const hrefArray = await this.scrapeHtmlForTagAttribute(html, 'a',   'href')                 const hrefArrayWithoutUndefineds =   this.#removeUndefinedFromArray(hrefArray)                    return hrefArrayWithoutUndefineds       }    ```                                                                                                                                                                                                                                                                                                                                                                    |     4                                   |     Don’t   repeat yourself: scrapeHtmlForTags och scrapeHtmlForTagAttribute används flera   gånger inom modulen och på så sätt håller jag antalet rader kod nere samt att   funktionsnamnen är lättare att förstå än själva koden.                                                                                                                                                                                                                 |



                   |                                              |

## Laborationsreflektion
Reflektera över uppgiften utifrån ett kodkvalitetsperspektiv. Använd begrepp ifrån boken. 

**Det har definitivt varit en annorlunda upplevelse med denna uppgift i jämförelse med de tidigare uppgifter jag har haft i andra kurser. Jag vill inte påstå att uppgiften i sig har varit svårare eller mer komplicerad än i de andra kurserna, men utgångspunkten har varit annorlunda och tidigare arbetssätt ifrågasätts.** 


**I tidigare kurser har fokuset legat på att göra rätt i den mån att man ska göra som man blir tillsagd och följa en standard. Jag ser mig själv som duktig på att följa instruktioner och leverera. I denna kurs har jag nu i stället fått möjligheter att börja undersöka och fråga: men vad är ”rätt” då? Rätt är inte längre hugget i sten. Min tidigare definition av Clean Code var coola one-liners och generellt så lite kod som möjligt i en fil. Nu ekar readability och understandability i huvudet. Jag ser hellre någon extra rad som ökar läsbarheten eller utbruten kod i bra namngivna funktioner som ökar förståelsen.** 


**Nu ändrades också mottagaren av min kod från endast lärare till en rad möjliga olika mottagare. Inte bara eftersom vi i workshops nu kodar med varandra utan också för att detta är första gången jag faktiskt har publicerat något publikt på GitHub. Jag kan inte längre anta att personen som läser min kod förstår bakgrunden till projektet eller sitter på en viss kompetens. Detta är något jag märkt att jag tänkt extra på under både utvecklingen samt dokumentationen av projektet.**